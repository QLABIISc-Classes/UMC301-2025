{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b80cf79",
   "metadata": {},
   "source": [
    "# Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4a1c89",
   "metadata": {},
   "source": [
    "Key Benefits\n",
    "\n",
    "- **Enhanced Functionality**: Perform complex tasks like data retrieval, calculations, or command execution.\n",
    "- **Structured Outputs**: Ensure outputs match predefined schemas for seamless data processing.\n",
    "- **Dynamic Decision-Making**: Invoke appropriate tools based on conversation context for intelligent interactions.\n",
    "- **Seamless Integration**: Enable smooth information flow across tools and components in workflows.\n",
    "- **Improved User Experience**: Provide accurate, relevant responses using real-time data or calculations.\n",
    "- **Flexibility & Customization**: Create custom tools to meet specific needs, enhancing application adaptability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728a4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947624fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model=\"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7881ade4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm unable to provide real-time weather updates. For the latest weather information in Bangalore, I recommend checking a reliable weather website or app.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 16, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BdWWbeeD8Nd3JTbvIMtlkvk6RZOT9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a27a8e2-5430-4879-88bb-44c80c245e35-0', usage_metadata={'input_tokens': 16, 'output_tokens': 27, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How will the weather be in Bangalore today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9676942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "#defining different tools\n",
    "\n",
    "# @tool decorator creates LangChain tools\n",
    "\n",
    "@tool\n",
    "def fake_weather_api(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Check the weather in a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city where you want to check the weather.\n",
    "\n",
    "    Returns:\n",
    "        str: A description of the current weather in the specified city.\n",
    "    \"\"\"\n",
    "    return \"Sunny, 22°C\"  #this could be an external API, like Google Weather\n",
    "\n",
    "\n",
    "@tool\n",
    "def outdoor_seating_availability(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Check if outdoor seating is available at a specified restaurant in a given city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city where you want to check for outdoor seating availability.\n",
    "\n",
    "    Returns:\n",
    "        str: A message stating whether outdoor seating is available or not.\n",
    "    \"\"\"\n",
    "    return \"Outdoor seating is available.\"\n",
    "\n",
    "\n",
    "tools = [fake_weather_api, outdoor_seating_availability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1910e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools) # allows llms to access tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c146d1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bjLkW4ZMFCQM5zdIHrsnt1U9', 'function': {'arguments': '{\"city\":\"Bangalore\"}', 'name': 'fake_weather_api'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 157, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BdWbUxVTJHSdu4DRhRrYpI1RoF2zu', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7c79a35c-92c9-466c-98dd-ae3387dacddc-0', tool_calls=[{'name': 'fake_weather_api', 'args': {'city': 'Bangalore'}, 'id': 'call_bjLkW4ZMFCQM5zdIHrsnt1U9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 157, 'output_tokens': 16, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_with_tools.invoke(\"How will the weather be in Bangalore today?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61940114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        \"How will the weather be in Bangalore today? Do you still have seats outdoor available?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "result = llm_with_tools.invoke(messages)  #this only decides the tool to call\n",
    "messages.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa2dc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fake_weather_api',\n",
       "  'args': {'city': 'Bangalore'},\n",
       "  'id': 'call_5lkWIb917nz2Cmi1Tz4FCvT9',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'outdoor_seating_availability',\n",
       "  'args': {'city': 'Bangalore'},\n",
       "  'id': 'call_YZMmWow4Hvdz9HTMoS2LdxxH',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d728be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {\n",
    "    \"fake_weather_api\": fake_weather_api,\n",
    "    \"outdoor_seating_availability\": outdoor_seating_availability,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1d606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Iterate over each tool call in the result's tool_calls list\n",
    "for tool_call in result.tool_calls:\n",
    "\n",
    "    # Retrieve the corresponding tool from the tool_mapping dictionary using the tool name (case insensitive)\n",
    "    tool = tool_mapping[tool_call[\"name\"].lower()]\n",
    "\n",
    "    # Invoke the selected tool with the provided arguments and store the output\n",
    "    tool_output = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    # Create a ToolMessage object with the tool's output and the unique ID of the tool call\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3aaf0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='How will the weather be in Bangalore today? Do you still have seats outdoor available?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5lkWIb917nz2Cmi1Tz4FCvT9', 'function': {'arguments': '{\"city\": \"Bangalore\"}', 'name': 'fake_weather_api'}, 'type': 'function'}, {'id': 'call_YZMmWow4Hvdz9HTMoS2LdxxH', 'function': {'arguments': '{\"city\": \"Bangalore\"}', 'name': 'outdoor_seating_availability'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 165, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BdWbxhNU2tYjK6aV4gRvG9rnduSr4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ce8b5448-3b81-4150-9b65-0aa686e2e367-0', tool_calls=[{'name': 'fake_weather_api', 'args': {'city': 'Bangalore'}, 'id': 'call_5lkWIb917nz2Cmi1Tz4FCvT9', 'type': 'tool_call'}, {'name': 'outdoor_seating_availability', 'args': {'city': 'Bangalore'}, 'id': 'call_YZMmWow4Hvdz9HTMoS2LdxxH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 165, 'output_tokens': 51, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Sunny, 22°C', tool_call_id='call_5lkWIb917nz2Cmi1Tz4FCvT9'),\n",
       " ToolMessage(content='Outdoor seating is available.', tool_call_id='call_YZMmWow4Hvdz9HTMoS2LdxxH')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a24056b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The weather in Bangalore today is sunny with a temperature of 22°C. Additionally, outdoor seating is available at restaurants in the area.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 244, 'total_tokens': 272, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-Bd5gOxiDmnZlkC9e43HhPZrysMx4p', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f689c75f-009d-4fb0-90bb-a1ef9f28e020-0', usage_metadata={'input_tokens': 244, 'output_tokens': 28, 'total_tokens': 272, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb795d",
   "metadata": {},
   "source": [
    "## Math Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbac7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af273e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x137791450>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x134f97250>, root_client=<openai.OpenAI object at 0x1371dfeb0>, root_async_client=<openai.AsyncOpenAI object at 0x137284490>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x137791450>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x134f97250>, root_client=<openai.OpenAI object at 0x1371dfeb0>, root_async_client=<openai.AsyncOpenAI object at 0x137284490>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tool_names = [\"llm-math\"]\n",
    "tools = load_tools(tool_names, llm=llm)\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a5e0a",
   "metadata": {},
   "source": [
    "### React Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37007bd8",
   "metadata": {},
   "source": [
    "ReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia) to incorporate additional information into the reasoning. The figure below shows an example of ReAct and the different steps involved to perform question answering.\n",
    "\n",
    "![](react.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dc02fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, # Zero shot react prompt\n",
    "                         verbose=True,\n",
    "                         max_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40276193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question about how many members the A Team has, I need to consider what \"A Team\" refers to. Typically, the A Team refers to a fictional group of characters from a television show. I will recall that the original A Team consists of four main members.\n",
      "\n",
      "Final Answer: The A Team has 4 members.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many members does the A Team have?',\n",
       " 'output': 'The A Team has 4 members.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(input=\"How many members does the A Team have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e407efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo solve the question, I need to first calculate the product of 100 multiplied by 100, and then I will find the square root of that result.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: 100 * 100\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 10000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the product, which is 10,000, I need to calculate the square root of this number.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: 10000 ** 0.5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 100.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 100.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 100 multiplied by 100? What is the square root of that number?',\n",
       " 'output': '100.0'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(input=\"What is 100 multiplied by 100? What is the square root of that number?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
